{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install everything\n",
    "Install this fork for Warp-CTC bindings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SeanNaren/warp-ctc.git\n",
    "!cd warp-ctc\n",
    "!mkdir build; cd build\n",
    "!cmake ..\n",
    "!make\n",
    "!export CUDA_HOME=\"/usr/local/cuda\"\n",
    "!cd ../pytorch_binding\n",
    "!python setup.py install\n",
    "! cd ..\n",
    "! cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pytorch audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install sox libsox-dev libsox-fmt-all\n",
    "! git clone https://github.com/pytorch/audio.git\n",
    "! cd audio\n",
    "! pip install cffi\n",
    "! python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install deepspeech.pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/SeanNaren/deepspeech.pytorch.git\n",
    "! cd deepspeech.pytorch\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sys, random, os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav48path = 'warp-ctc/VCTK-Corpus/wav48/p266'\n",
    "txtpath = 'warp-ctc/VCTK-Corpus/txt'\n",
    "wav48 = []\n",
    "txt = []\n",
    "wav48 = wav48 + [wav48path + '/' + f for f in listdir(wav48path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [file.replace('wav48', 'txt').replace('.wav', '.txt') for file in wav48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in txt:\n",
    "    if not os.path.exists(t):\n",
    "        print(t)\n",
    "        txt.remove(t)\n",
    "        wav48.remove(t.replace('txt', 'wav48').replace('.txt', '.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(list(zip(wav48, txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warp-ctc/VCTK-Corpus/wav48/p266/p266_151.wav</td>\n",
       "      <td>warp-ctc/VCTK-Corpus/txt/p266/p266_151.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warp-ctc/VCTK-Corpus/wav48/p266/p266_419.wav</td>\n",
       "      <td>warp-ctc/VCTK-Corpus/txt/p266/p266_419.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>warp-ctc/VCTK-Corpus/wav48/p266/p266_224.wav</td>\n",
       "      <td>warp-ctc/VCTK-Corpus/txt/p266/p266_224.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>warp-ctc/VCTK-Corpus/wav48/p266/p266_257.wav</td>\n",
       "      <td>warp-ctc/VCTK-Corpus/txt/p266/p266_257.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>warp-ctc/VCTK-Corpus/wav48/p266/p266_366.wav</td>\n",
       "      <td>warp-ctc/VCTK-Corpus/txt/p266/p266_366.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0  \\\n",
       "0  warp-ctc/VCTK-Corpus/wav48/p266/p266_151.wav   \n",
       "1  warp-ctc/VCTK-Corpus/wav48/p266/p266_419.wav   \n",
       "2  warp-ctc/VCTK-Corpus/wav48/p266/p266_224.wav   \n",
       "3  warp-ctc/VCTK-Corpus/wav48/p266/p266_257.wav   \n",
       "4  warp-ctc/VCTK-Corpus/wav48/p266/p266_366.wav   \n",
       "\n",
       "                                            1  \n",
       "0  warp-ctc/VCTK-Corpus/txt/p266/p266_151.txt  \n",
       "1  warp-ctc/VCTK-Corpus/txt/p266/p266_419.txt  \n",
       "2  warp-ctc/VCTK-Corpus/txt/p266/p266_224.txt  \n",
       "3  warp-ctc/VCTK-Corpus/txt/p266/p266_257.txt  \n",
       "4  warp-ctc/VCTK-Corpus/txt/p266/p266_366.txt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_pd = pandas.DataFrame(train_data)\n",
    "train_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pd.to_csv(\"train.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pd = pandas.DataFrame(test_data)\n",
    "test_data_pd.to_csv(\"test.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Save directory already exists.\n",
      "DeepSpeech(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "    (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
      "  )\n",
      "  (rnns): Sequential(\n",
      "    (0): BatchRNN(\n",
      "      (rnn): GRU(672, 800, bias=False, bidirectional=True)\n",
      "    )\n",
      "    (1): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "    )\n",
      "    (2): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "    )\n",
      "    (3): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "    )\n",
      "    (4): BatchRNN(\n",
      "      (batch_norm): SequenceWise (\n",
      "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True))\n",
      "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): SequenceWise (\n",
      "    Sequential(\n",
      "      (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (1): Linear(in_features=800, out_features=29, bias=False)\n",
      "    ))\n",
      "  )\n",
      "  (inference_softmax): InferenceBatchSoftmax(\n",
      "  )\n",
      ")\n",
      "Number of parameters: 38067968\n",
      "Epoch: [1][1/79]\tTime 66.063 (66.063)\tData 0.330 (0.330)\tLoss 1412.8754 (1412.8754)\t\n",
      "Epoch: [1][2/79]\tTime 35.726 (50.895)\tData 0.002 (0.166)\tLoss 849.7051 (1131.2902)\t\n",
      "Epoch: [1][3/79]\tTime 53.817 (51.869)\tData 0.003 (0.112)\tLoss 315.3399 (859.3068)\t\n",
      "Epoch: [1][4/79]\tTime 73.988 (57.399)\tData 0.005 (0.085)\tLoss 278.2052 (714.0314)\t\n",
      "Epoch: [1][5/79]\tTime 66.539 (59.227)\tData 0.001 (0.068)\tLoss 61.0737 (583.4399)\t\n",
      "Epoch: [1][6/79]\tTime 58.034 (59.028)\tData 0.003 (0.058)\tLoss 21.8937 (489.8488)\t\n",
      "Epoch: [1][7/79]\tTime 52.156 (58.046)\tData 0.003 (0.050)\tLoss 37.4113 (425.2149)\t\n",
      "Epoch: [1][8/79]\tTime 50.457 (57.098)\tData 0.006 (0.044)\tLoss 29.5532 (375.7572)\t\n",
      "Epoch: [1][9/79]\tTime 63.550 (57.815)\tData 0.001 (0.039)\tLoss 15.0393 (335.6774)\t\n",
      "Epoch: [1][10/79]\tTime 58.076 (57.841)\tData 0.004 (0.036)\tLoss 76.6986 (309.7795)\t\n",
      "Epoch: [1][11/79]\tTime 101.598 (61.819)\tData 0.005 (0.033)\tLoss 15.1343 (282.9936)\t\n",
      "Epoch: [1][12/79]\tTime 48.222 (60.686)\tData 0.004 (0.031)\tLoss 53.4456 (263.8646)\t\n",
      "Epoch: [1][13/79]\tTime 46.511 (59.595)\tData 0.003 (0.029)\tLoss 19.8614 (245.0951)\t\n",
      "Epoch: [1][14/79]\tTime 73.848 (60.613)\tData 0.003 (0.027)\tLoss 16.5281 (228.7689)\t\n",
      "Epoch: [1][15/79]\tTime 56.350 (60.329)\tData 0.004 (0.025)\tLoss 23.9592 (215.1149)\t\n",
      "Epoch: [1][16/79]\tTime 54.379 (59.957)\tData 0.004 (0.024)\tLoss 10.4712 (202.3247)\t\n",
      "Epoch: [1][17/79]\tTime 78.871 (61.070)\tData 0.004 (0.023)\tLoss 15.7828 (191.3516)\t\n"
     ]
    }
   ],
   "source": [
    "%run deepspeech.pytorch/train.py --train-manifest train.csv --val-manifest test.csv --epochs 3 --batch-size 4 --labels-path=deepspeech.pytorch/labels.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
